"""
Modeling Analysis: Evaluation Metrics Deep Dive (Task 5.2)

Goal: Analyze regression residuals and compute classification metrics.
Input: reports/results/regression_predictions.csv (Generated by Task 5.1)

Analysis:
1. Residual Analysis (Linear Assumptions):
   - Residuals vs Predicted (Homoscedasticity)
   - Residual Distribution (Normality)
   - Q-Q Plot
2. Classification Metrics (from Regression):
   - Threshold target at mean/median to create binary 'High Activity' class.
   - Calculate Accuracy, Precision, Recall, F1, ROC-AUC.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy import stats
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,
    confusion_matrix, roc_curve, precision_recall_curve
)

def load_predictions():
    path = Path('reports/results/regression_predictions.csv')
    if not path.exists():
        raise FileNotFoundError(f"{path} not found. Run Task 5.1 script first.")
    return pd.read_csv(path)

def plot_residuals(df, model_col='Ridge'):
    """Generate residual plots."""
    y_true = df['y_true']
    y_pred = df[model_col]
    residuals = y_true - y_pred
    
    out_dir = Path('reports/figures/modeling')
    out_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. Residuals vs Predicted
    plt.figure(figsize=(10, 6))
    plt.scatter(y_pred, residuals, alpha=0.3, s=10)
    plt.axhline(0, color='red', linestyle='--')
    plt.xlabel('Predicted Value')
    plt.ylabel('Residuals')
    plt.title(f'Residuals vs Predicted ({model_col})')
    plt.savefig(out_dir / 'residuals_vs_predicted.png')
    plt.close()
    
    # 2. Residual Distribution
    plt.figure(figsize=(10, 6))
    sns.histplot(residuals, kde=True, bins=50)
    plt.title(f'Residual Distribution ({model_col})')
    plt.xlabel('Residual Error')
    plt.savefig(out_dir / 'residuals_dist.png')
    plt.close()
    
    # 3. Q-Q Plot
    plt.figure(figsize=(10, 6))
    stats.probplot(residuals, dist="norm", plot=plt)
    plt.title(f'Q-Q Plot ({model_col})')
    plt.savefig(out_dir / 'residuals_qq.png')
    plt.close()
    
    print(f"Residual plots saved to {out_dir}")

def analyze_classification(df, model_col='Ridge'):
    """Convert regression to classification and calculate metrics."""
    # Threshold: Is activity above valid Mean? (or arbitrary 60 mins/day?)
    # activity_active_minutes is the target.
    # Let's see the distribution summary
    threshold = df['y_true'].mean()
    print(f"\n--- Classification Analysis (Threshold = Mean = {threshold:.2f}) ---")
    
    # Binarize
    y_true_binary = (df['y_true'] > threshold).astype(int)
    y_pred_binary = (df[model_col] > threshold).astype(int)
    
    # Metrics
    acc = accuracy_score(y_true_binary, y_pred_binary)
    prec = precision_score(y_true_binary, y_pred_binary)
    rec = recall_score(y_true_binary, y_pred_binary)
    f1 = f1_score(y_true_binary, y_pred_binary)
    auc = roc_auc_score(y_true_binary, df[model_col]) # Use continuous score for AUC
    
    print(f"Accuracy:  {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall:    {rec:.4f}")
    print(f"F1 Score:  {f1:.4f}")
    print(f"ROC-AUC:   {auc:.4f}")
    
    # Confusion Matrix
    cm = confusion_matrix(y_true_binary, y_pred_binary)
    print("\nConfusion Matrix:")
    print(pd.DataFrame(cm, 
                       index=['Actual Low', 'Actual High'], 
                       columns=['Pred Low', 'Pred High']))
                       
    return {
        'Accuracy': acc,
        'Precision': prec,
        'Recall': rec,
        'F1': f1,
        'AUC': auc
    }

def main():
    print("--- Task 5.2: Evaluation Metrics Deep Dive ---")
    try:
        df = load_predictions()
        plot_residuals(df, model_col='Ridge')
        metrics = analyze_classification(df, model_col='Ridge')
        
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()
