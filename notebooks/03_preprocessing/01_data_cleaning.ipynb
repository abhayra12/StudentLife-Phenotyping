{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Cleaning Pipeline Application\n",
                "\n",
                "**Objective**: Apply cleaning pipeline to all 10 sensors for Tier 1 participants.\n",
                "\n",
                "**Steps**:\n",
                "1. Load Tier 1 participants (from Phase 2)\n",
                "2. For each sensor:\n",
                "   - Validate timestamps\n",
                "   - Validate values\n",
                "   - Detect outliers\n",
                "   - Handle missing data\n",
                "3. Save cleaned data to `data/processed/cleaned/`\n",
                "4. Generate cleaning report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(str(Path('../../').resolve()))\n",
                "\n",
                "from src.data.cleaning import (\n",
                "    validate_timestamps, \n",
                "    validate_values, \n",
                "    detect_outliers, \n",
                "    handle_missing_data\n",
                ")\n",
                "\n",
                "sns.set_style('whitegrid')\n",
                "\n",
                "# Paths\n",
                "RAW_PATH = Path('../../data/raw/dataset/sensing')\n",
                "PROCESSED_PATH = Path('../../data/processed/cleaned')\n",
                "PROCESSED_PATH.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Load Tier 1 participants\n",
                "tiers_df = pd.read_csv('../../data/processed/participant_tiers.csv')\n",
                "tier1_participants = tiers_df[tiers_df['quality_tier'] == 'Tier 1: Excellent']['participant'].tolist()\n",
                "\n",
                "print(f\"Loaded {len(tier1_participants)} Tier 1 participants\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cleaning Pipeline Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_sensor_data(sensor_name, participant_id):\n",
                "    \"\"\"Run full cleaning pipeline for one sensor/participant.\"\"\"\n",
                "    # 1. Load data\n",
                "    sensor_dir = RAW_PATH / sensor_name\n",
                "    files = list(sensor_dir.glob(f\"*{participant_id}*.csv\"))\n",
                "    \n",
                "    if not files:\n",
                "        return None, None\n",
                "        \n",
                "    df = pd.read_csv(files[0])\n",
                "    original_len = len(df)\n",
                "    report = {'sensor': sensor_name, 'participant': participant_id, 'original_rows': original_len}\n",
                "    \n",
                "    # 2. Validate Timestamps\n",
                "    time_col = 'timestamp' if 'timestamp' in df.columns else ('start_timestamp' if 'start_timestamp' in df.columns else None)\n",
                "    \n",
                "    if time_col:\n",
                "        df, time_issues = validate_timestamps(df, time_col)\n",
                "        report.update(time_issues)\n",
                "    else:\n",
                "        report['time_error'] = 'No timestamp column'\n",
                "        return df, report\n",
                "        \n",
                "    # 3. Validate Values\n",
                "    df, value_issues = validate_values(df, sensor_name)\n",
                "    for k, v in value_issues.items():\n",
                "        report[f'invalid_{k}'] = v\n",
                "        \n",
                "    # 4. Outlier Detection (for specific numeric columns)\n",
                "    outlier_cols = []\n",
                "    if sensor_name == 'conversation':\n",
                "        outlier_cols = ['duration'] if 'duration' in df.columns else []\n",
                "    elif sensor_name == 'bluetooth':\n",
                "        outlier_cols = ['class_id'] # Example\n",
                "        \n",
                "    outliers_removed = 0\n",
                "    for col in outlier_cols:\n",
                "        if col in df.columns:\n",
                "            outlier_idx = detect_outliers(df, col, method='iqr')\n",
                "            outliers_removed += len(outlier_idx)\n",
                "            df = df.drop(outlier_idx)\n",
                "            \n",
                "    report['outliers_removed'] = outliers_removed\n",
                "    \n",
                "    # 5. Handle Missing Data (if applicable)\n",
                "    # Usually we don't fill raw sensor data gaps unless resampling, \n",
                "    # but let's say we want to fill small gaps in continuous sensors like 'activity' if we were resampling.\n",
                "    # Here we just return the cleaned raw data.\n",
                "    \n",
                "    report['final_rows'] = len(df)\n",
                "    report['rows_removed'] = original_len - len(df)\n",
                "    \n",
                "    return df, report"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Pipeline on All Sensors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sensors = ['activity', 'conversation', 'gps', 'bluetooth', 'wifi', 'dark', 'phonelock', 'phonecharge', 'audio', 'wifi_location']\n",
                "all_reports = []\n",
                "\n",
                "for sensor in sensors:\n",
                "    print(f\"Processing {sensor}...\")\n",
                "    sensor_out_path = PROCESSED_PATH / sensor\n",
                "    sensor_out_path.mkdir(exist_ok=True)\n",
                "    \n",
                "    for pid in tier1_participants:\n",
                "        df_clean, report = clean_sensor_data(sensor, pid)\n",
                "        \n",
                "        if df_clean is not None:\n",
                "            # Save cleaned data\n",
                "            out_file = sensor_out_path / f\"{sensor}_{pid}.csv\"\n",
                "            df_clean.to_csv(out_file, index=False)\n",
                "            all_reports.append(report)\n",
                "\n",
                "reports_df = pd.DataFrame(all_reports)\n",
                "reports_df.to_csv('../../data/processed/cleaning_report.csv', index=False)\n",
                "print(\"\\nCleaning Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cleaning Summary Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summarize issues by sensor\n",
                "summary = reports_df.groupby('sensor')[['original_rows', 'rows_removed', 'future_timestamps', 'duplicates']].sum()\n",
                "summary['pct_removed'] = (summary['rows_removed'] / summary['original_rows']) * 100\n",
                "\n",
                "print(\"Cleaning Summary by Sensor:\")\n",
                "print(summary.round(2))\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.barplot(x=summary.index, y=summary['pct_removed'])\n",
                "plt.title('Percentage of Data Removed per Sensor')\n",
                "plt.ylabel('% Removed')\n",
                "plt.xticks(rotation=45)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.13.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}